defaults:
  - _self_
  - dataset: simcol
  - model: small
  - trainer: default

hydra:
  run:
    dir: configs/experiments/${dataset.ds_type}/m${model.encoder}_el${model.encoder_lr}_dl${model.decoder_lr}_b${dataset.batch_size}_e${trainer.max_epochs}_d${dataset.ds_type}_p${model.pct_start}

# dataset:
#   - ds_type: "simcol"
#   # SimCol3D: splits as per https://github.com/ESandML/SimCol-Entry/blob/main/train.py
#   - simcol_data_dir: './datasets/SyntheticColon/'
#   - simcol_train_list: './datasets/SyntheticColon/train.txt'
#   - simcol_val_list: './datasets/SyntheticColon/val.txt'
#   - simcol_test_list: './datasets/SyntheticColon/test.txt'
#   # C3VD: splits as per https://github.com/yahskapar/PPSNet/tree/main/C3VD_splits
#   - c3vd_data_dir: './datasets/C3VD/'
#   - c3vd_train_list: './datasets/C3VD/train.txt'
#   - c3vd_val_list: './datasets/C3VD/val.txt'
#   - batch_size: 64
#   - num_workers: 8
#   - size: 518

# model:
#   - encoder: vitl
#   - min_depth: 0.000001
#   - simcol_max_depth: 20.0 # 0-20 cm - from SimCol3D main paper
#   - c3vd_max_depth: 100.0 # 0-100 mm - from C3VD main paper
#   - pct_start: 0.1 # warmup phase
#   - encoder_lr: 5e-6 # encoder lr according to https://arxiv.org/pdf/2409.16277
#   - decoder_lr: 5e-5 # decoder lr according to https://arxiv.org/pdf/2409.16277
#   - max_encoder_lr: 5e-5
#   - max_decoder_lr: 5e-4

# trainer:
#   - devices: [0]
#   - max_epochs: 30
#   - log_every_n_steps: 100
#   - precision: '16-mixed'
#   - gradient_clip_val: 1.0
#   - val_check_interval: 0.5
  